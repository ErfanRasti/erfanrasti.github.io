---
title: |
  A User-Centric Energy-Saving Method for Dynamic 5G Heterogeneous Networks Using Deep Reinforcement Learning
authors:
  - Mohammad Ali Arami
  - admin
  - Abbas Mohammadi
author_notes:
  - "Equal contribution"
  - "Equal contribution"
date: "2025-10-20"

# Schedule page publish date (NOT publication's date).
publishDate: "2025-06-24"

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article-journal"]

# Publication name and optional abbreviated publication name.
publication: "**IEEE Transactions on Mobile Computing**"
publication_short: "IEEE-TMC"

abstract: |
  <p style="text-align: justify;">Energy consumption (EC) represents a significant challenge for 5G and 6G mobile networks, necessitating a primary focus on optimizing energy savings (ES). This paper illustrates the practical benefits of a user-centric deep reinforcement learning (DRL) models in achieving a green cellular network. The primary objective is to optimize energy usage in a heterogeneous network (HetNet). The optimization of power consumption (PC) in such networks is a non-convex and NP-hard problem. To address this challenge, we propose using reinforcement learning (RL). Due to the extensive state and action space, classical RL approaches are unsuitable. Therefore, the adoption of DRL methods, notably the deep Q-network (DQN) and deep deterministic policy gradient (DDPG) methods, is necessary. The proposed approach entails a user-centric connection establishment, whereby small base stations (SBSs) are switched to an on mode. The mode switching determined by the DRL methods is controlled by an anti-abrupt transition mechanism, which prevents unnecessary oscillations in the network. The results are benchmarked against existing approaches, specifically genetic algorithm (GA) and particle swarm optimization (PSO) for ES. The proposed methods outperform both GA and PSO optimization techniques in terms of ES and significantly reduce time consumption, enhancing its practical implementation feasibility.</p>
# Summary. An optional shortened abstract.
summary: In this project, we design a user-centric algorithm utilizing deep reinforcement learning to minimize the total power consumption of the network while also considering the optimality of the aggregate delay.
tags:
  - Mobile Computing
featured: true

links:
  - type: pdf
    url: https://ieeexplore.ieee.org/document/11049041

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  focal_point: ""
  preview_only: false
# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
# projects: []
# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
---
